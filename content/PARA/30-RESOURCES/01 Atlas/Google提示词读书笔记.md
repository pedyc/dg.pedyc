---
title: Google提示词读书笔记
date-created: 2025-08-28
date-modified: 2025-08-28
categories: [读书笔记]
---

## AI 摘要

这是一篇关于提示工程（Prompt Engineering）的技术白皮书，主要介绍了如何通过设计有效的提示（prompt）来引导大型语言模型（LLM）生成准确的输出。文章详细讨论了提示工程的各个方面，包括提示技术、模型配置、最佳实践等。以下是对这些核心内容的简要概述：

1. 提示工程简介：
	 - 提示工程是设计高质量提示以引导 LLM 产生准确输出的过程。
	 - 影响提示效果的因素包括模型选择、训练数据、模型配置、词汇选择、风格和语气、结构及上下文等。
	 - 提示工程是一个迭代过程，不充分的提示可能导致模糊或不准确的响应。
2. LLM 输出配置：
	 - 输出长度：生成更多的标记需要更多的计算，可能导致更高的能耗和成本。
	 - 采样控制：包括温度、Top-K 和 Top-P 设置，这些配置决定标记概率的处理方式，影响生成文本的随机性和多样性。
	 - 温度控制：低温度适合确定性响应，高温度可能导致更多样化的结果。
	 - Top-K 和 Top-P 采样：Top-K 选择最可能的 K 个标记，Top-P 选择累积概率不超过 P 的标记。
3. 提示技术：
	 - 零样本提示（Zero-shot）：仅提供任务描述和输入文本。
	 - 一样本提示（One-shot）和少样本提示（Few-shot）：提供单个或多个示例帮助模型理解任务。
	 - 系统提示（System Prompting）：定义模型的总体能力和目标。
	 - 角色提示（Role Prompting）：为模型分配特定角色以生成符合角色特性的输出。
	 - 上下文提示（Contextual Prompting）：提供与当前任务相关的具体细节或背景信息。
4. 高级提示技术：
	 - 退后提示（Step-back Prompting）：先考虑与任务相关的一般问题，再将答案用于具体任务。
	 - 思维链提示（Chain of Thought Prompting）：生成中间推理步骤以提高回答准确性。
	 - 自洽性提示（Self-consistency）：通过采样和多数投票生成多样化的推理路径，选择最一致的答案。
	 - 思维树提示（Tree of Thoughts Prompting）：同时探索多个不同的推理路径。
	 - 理解与行动提示（ReAct Prompting）：结合推理和外部工具（如搜索、代码解释器）来解决问题。
5. 代码提示：
	 - 编写代码提示：LLM 可以帮助生成特定编程语言的代码片段。
	 - 解释代码提示：LLM 可以解释代码段的功能和操作。
	 - 翻译代码提示：LLM 可以将代码从一种编程语言翻译成另一种。
	 - 调试和审查代码提示：LLM 可以帮助识别和修复代码中的错误。
6. 最佳实践：
	 - 提供示例：在提示中包含示例以展示期望的输出模式。
	 - 设计简洁：提示应简洁明了，避免不必要的复杂性。
	 - 明确输出要求：具体说明期望的输出格式和内容。
	 - 使用指令而非约束：优先使用正面的指令来指导模型，而非限制其行为。
	 - 控制标记长度：设置输出标记的最大长度以优化性能和成本。
	 - 使用变量：在提示中使用变量以增加灵活性和重用性。
	 - 适应模型更新：随着模型架构和能力的更新，调整提示以利用新特性。
7. 多模态提示：
	 - 多模态提示结合文本、图像、音频等多种输入格式来引导模型，适用于更复杂和多样化的任务。

这篇文章为理解和使用提示工程以优化大型语言模型的输出提供了全面的指导，通过详细的技术介绍和最佳实践，帮助读者提高提示设计的能力和效果。

## 怎样合理的编写提示词？

## 参考链接

- [[Google_Prompt Engineering_v7.pdf]]
